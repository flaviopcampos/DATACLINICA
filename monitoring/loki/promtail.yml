# =============================================================================
# Configuração do Promtail - DataClinica
# Agente de coleta de logs para o Loki
# =============================================================================

# Configurações do servidor
server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info
  log_format: logfmt

# Configurações de posições (onde o Promtail salva o progresso de leitura)
positions:
  filename: /tmp/positions.yaml

# Configurações do cliente Loki
clients:
  - url: http://loki:3100/loki/api/v1/push
    tenant_id: dataclinica
    
    # Configurações de batching
    batchwait: 1s
    batchsize: 1048576  # 1MB
    
    # Configurações de retry
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10
    
    # Configurações de timeout
    timeout: 10s
    
    # Configurações de external labels
    external_labels:
      cluster: dataclinica
      environment: ${ENVIRONMENT:-development}
      job: promtail

# Configurações de scraping
scrape_configs:
  # =============================================================================
  # Logs do Sistema
  # =============================================================================
  - job_name: system-logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: system
          __path__: /var/log/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="system"}'
          stages:
            - regex:
                expression: '^(?P<timestamp>\S+\s+\S+\s+\S+)\s+(?P<hostname>\S+)\s+(?P<service>\S+)\[(?P<pid>\d+)\]:\s+(?P<message>.*)$'
            - labels:
                hostname:
                service:
                pid:
            - timestamp:
                source: timestamp
                format: 'Jan 02 15:04:05'
                location: 'America/Sao_Paulo'

  # =============================================================================
  # Logs de Containers Docker
  # =============================================================================
  - job_name: docker-containers
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["logging=promtail"]
    
    relabel_configs:
      # Extrair nome do container
      - source_labels: ['__meta_docker_container_name']
        regex: '/(.*?)'
        target_label: 'container_name'
      
      # Extrair imagem do container
      - source_labels: ['__meta_docker_container_image']
        target_label: 'image'
      
      # Extrair labels do container
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'compose_service'
      
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'compose_project'
      
      # Definir path dos logs
      - source_labels: ['__meta_docker_container_id']
        target_label: '__path__'
        replacement: '/var/lib/docker/containers/$1/$1-json.log'
    
    pipeline_stages:
      - json:
          expressions:
            output: log
            stream: stream
            timestamp: time
      
      - timestamp:
          source: timestamp
          format: RFC3339Nano
      
      - output:
          source: output
      
      - labels:
          stream:

  # =============================================================================
  # Logs do DataClinica Backend
  # =============================================================================
  - job_name: dataclinica-backend
    static_configs:
      - targets:
          - localhost
        labels:
          job: dataclinica-backend
          service: backend
          __path__: /var/log/dataclinica/backend/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="dataclinica-backend"}'
          stages:
            - json:
                expressions:
                  timestamp: timestamp
                  level: level
                  logger: logger
                  message: message
                  module: module
                  function: function
                  line: line
                  user_id: user_id
                  request_id: request_id
                  ip_address: ip_address
                  method: method
                  url: url
                  status_code: status_code
                  response_time: response_time
            
            - labels:
                level:
                logger:
                module:
                user_id:
                request_id:
                method:
                status_code:
            
            - timestamp:
                source: timestamp
                format: RFC3339
            
            # Filtrar logs de debug em produção
            - drop:
                expression: '.*'
                older_than: 24h
                source: level
                value: DEBUG
                drop_counter_reason: debug_in_production

  # =============================================================================
  # Logs do DataClinica Frontend (Nginx)
  # =============================================================================
  - job_name: dataclinica-frontend
    static_configs:
      - targets:
          - localhost
        labels:
          job: dataclinica-frontend
          service: frontend
          __path__: /var/log/nginx/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="dataclinica-frontend"}'
          stages:
            - regex:
                expression: '^(?P<remote_addr>\S+)\s+-\s+(?P<remote_user>\S+)\s+\[(?P<time_local>[^\]]+)\]\s+"(?P<method>\S+)\s+(?P<request_uri>\S+)\s+(?P<server_protocol>\S+)"\s+(?P<status>\d+)\s+(?P<body_bytes_sent>\d+)\s+"(?P<http_referer>[^"]*)"\s+"(?P<http_user_agent>[^"]*)"\s+"(?P<http_x_forwarded_for>[^"]*)"\s+(?P<request_time>\S+)\s+(?P<upstream_response_time>\S+)$'
            
            - labels:
                method:
                status:
                remote_addr:
            
            - timestamp:
                source: time_local
                format: '02/Jan/2006:15:04:05 -0700'
            
            # Adicionar métricas de performance
            - metrics:
                request_duration_seconds:
                  type: Histogram
                  description: "Duration of HTTP requests"
                  source: request_time
                  config:
                    buckets: [0.1, 0.5, 1.0, 2.5, 5.0, 10.0]
                
                http_requests_total:
                  type: Counter
                  description: "Total HTTP requests"
                  config:
                    action: inc

  # =============================================================================
  # Logs do PostgreSQL
  # =============================================================================
  - job_name: postgresql
    static_configs:
      - targets:
          - localhost
        labels:
          job: postgresql
          service: database
          __path__: /var/log/postgresql/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="postgresql"}'
          stages:
            - regex:
                expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(?P<timezone>\S+)\s+\[(?P<pid>\d+)\]\s+(?P<level>\w+):\s+(?P<message>.*)$'
            
            - labels:
                level:
                pid:
            
            - timestamp:
                source: timestamp
                format: '2006-01-02 15:04:05.000'
                location: 'America/Sao_Paulo'
            
            # Detectar queries lentas
            - match:
                selector: '{job="postgresql"} |~ "duration:"'
                stages:
                  - regex:
                      expression: 'duration: (?P<duration>\d+\.\d+) ms'
                  - labels:
                      query_type: slow

  # =============================================================================
  # Logs do Redis
  # =============================================================================
  - job_name: redis
    static_configs:
      - targets:
          - localhost
        labels:
          job: redis
          service: cache
          __path__: /var/log/redis/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="redis"}'
          stages:
            - regex:
                expression: '^(?P<pid>\d+):(?P<role>\w+)\s+(?P<timestamp>\d{2}\s+\w{3}\s+\d{4}\s+\d{2}:\d{2}:\d{2}\.\d{3})\s+(?P<level>[\*\#\-\.])\s+(?P<message>.*)$'
            
            - labels:
                level:
                role:
                pid:
            
            - timestamp:
                source: timestamp
                format: '02 Jan 2006 15:04:05.000'
                location: 'America/Sao_Paulo'

  # =============================================================================
  # Logs de Auditoria
  # =============================================================================
  - job_name: audit-logs
    static_configs:
      - targets:
          - localhost
        labels:
          job: audit
          service: security
          __path__: /var/log/dataclinica/audit/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="audit"}'
          stages:
            - json:
                expressions:
                  timestamp: timestamp
                  event_type: event_type
                  user_id: user_id
                  user_email: user_email
                  ip_address: ip_address
                  user_agent: user_agent
                  resource: resource
                  action: action
                  result: result
                  details: details
            
            - labels:
                event_type:
                user_id:
                action:
                result:
            
            - timestamp:
                source: timestamp
                format: RFC3339

  # =============================================================================
  # Logs de Aplicações de Terceiros
  # =============================================================================
  - job_name: third-party-apps
    static_configs:
      - targets:
          - localhost
        labels:
          job: third-party
          __path__: /var/log/third-party/**/*.log
    
    pipeline_stages:
      - match:
          selector: '{job="third-party"}'
          stages:
            - multiline:
                firstline: '^\d{4}-\d{2}-\d{2}'
                max_wait_time: 3s
            
            - regex:
                expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})\s+(?P<level>\w+)\s+(?P<message>.*)$'
            
            - labels:
                level:
            
            - timestamp:
                source: timestamp
                format: '2006-01-02 15:04:05'
                location: 'America/Sao_Paulo'

# Configurações de limites
limits_config:
  readline_rate: 10000
  readline_burst: 20000

# Configurações de target
target_config:
  sync_period: 10s

# Configurações de tracing
tracing:
  enabled: true
  jaeger:
    agent:
      host: jaeger
      port: 6831
    sampler:
      type: const
      param: 0.1  # 10% sampling